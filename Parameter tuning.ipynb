{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters tuning tutorial\n",
    "\n",
    "As what we focus on how to find the best model parameters given the datasets, so how to find the best parameters is the key point. In fact, if we just construct the model using the default parameters no matter using sklearn module or other machine leaning module we could train a model, but what we need to do is to find the best parameters that could give us a higher accuracy or lower loss. So how to find the best parameters?\n",
    "\n",
    "There are two common ways that we could use to find the parameters that are best for our dataset, there are: Grid search and Random Search. One thing to notice is that: no matter which way we use, we couldn't find the best model!!! What we want to do is to find the sub-best model! useful tips that we could use for interview, really important!\n",
    "\n",
    "So here we start to use the sklearn to explain this two method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first to import the module\n",
    "import numpy as np\n",
    "from scipy.stats import distributions\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# I don't want to see the warning again!\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, this is a regression data\n",
    "x, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# train_test_split is the stractied data sample\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': False,\n",
       " 'random_state': None,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the algorithm object instance for later model parameters tuning\n",
    "# for the linear model for regression, there are 3 types model: linear regression, lasso, ridge. \n",
    "# The common part is Y = W*X means the linear function, but for the lasso and ridge regression is\n",
    "# added with regularization term, for lasso is added with l1-regulazation, \n",
    "# this would make the weights to be 0 for some feature dosen't provide much info;\n",
    "# for ridge regression is added with l2-regulazation term, this would make the weights to be more equally with each other.\n",
    "# For more, I will explain to you.\n",
    "lr = Ridge()\n",
    "\n",
    "# get the default parameters, the alpha is the regulazation term that we want to tune.\n",
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters accuracy:  3227.4560610246067\n"
     ]
    }
   ],
   "source": [
    "# train the model using the default parameters\n",
    "lr.fit(xtrain, ytrain)\n",
    "\n",
    "pred = lr.predict(xtest)\n",
    "\n",
    "base_loss = metrics.mean_squared_error(ytest, pred)\n",
    "\n",
    "# here is to use the mean squared error for evaluation: loss=sum((y - pred) ** 2)\n",
    "print(\"Default parameters accuracy: \", base_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search\n",
    "\n",
    "The grid search algorithm is really simple, as what you need to do is just to predefine what parameters that you want to tune, then for each step, model's parameters will be updated with you defined. \n",
    "One thing to notice is that, here we would use cross-validation to find the best model. About cross-validation, I will also expalin to you.\n",
    "\n",
    "Here we could start the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First way parameter: {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
      "Second way parameter: {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "# there are two ways to define the parameters, but both are with being created with dictionary data type \n",
    "# with key for parameter name and value is list or array for what we want to tune.\n",
    "# the first\n",
    "param_grid = {'alpha': [.0001, .001, .01, .1, 1, 10]}\n",
    "\n",
    "print(\"First way parameter:\", param_grid)\n",
    "\n",
    "# the second way\n",
    "alpha = [.0001, .001, .01, .1, 1, 10, 100]\n",
    "param_grid = dict(alpha=alpha)\n",
    "\n",
    "print(\"Second way parameter:\", param_grid)\n",
    "\n",
    "# you could see they are same! both ways works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation search, cv means: cross-validation \n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, cv=3, verbose=1)\n",
    "\n",
    "# start to fit the model on train data!\n",
    "# Noted: no matter which way we use or choose, we should just train the model with train data, \n",
    "# the test data should just use once when you evaluate your model\n",
    "grid_search.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.48875139903342185\n",
      "******************************\n",
      "Best find parameter: {'alpha': 0.001}\n",
      "Best fitted model:  Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "******************************\n",
      "training step evaluation metrics: dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_alpha', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n",
      "******************************\n",
      "model training step info:\n",
      "{'mean_fit_time': array([0.00133006, 0.00034237, 0.00165606, 0.00031964, 0.0006539 ,\n",
      "       0.00067862, 0.00065136]), 'std_fit_time': array([0.00046924, 0.00048418, 0.00095272, 0.00045204, 0.00046255,\n",
      "       0.00048014, 0.00046089]), 'mean_score_time': array([0.        , 0.00066471, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'std_score_time': array([0.        , 0.00047002, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'param_alpha': masked_array(data=[0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.0001}, {'alpha': 0.001}, {'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}, {'alpha': 100}], 'split0_test_score': array([0.49677817, 0.4991493 , 0.50198747, 0.50091197, 0.39978128,\n",
      "       0.12290848, 0.01379884]), 'split1_test_score': array([0.41169704, 0.4117156 , 0.41039678, 0.41280523, 0.34795135,\n",
      "       0.10764744, 0.00769035]), 'split2_test_score': array([0.55636542, 0.55595886, 0.55391827, 0.55116189, 0.42896992,\n",
      "       0.1237197 , 0.01389341]), 'mean_test_score': array([0.48808733, 0.4887514 , 0.48858295, 0.48811493, 0.39213012,\n",
      "       0.11807593, 0.01178826]), 'std_test_score': array([0.05933868, 0.0593043 , 0.05931583, 0.05716714, 0.03349368,\n",
      "       0.00739714, 0.00290407]), 'rank_test_score': array([4, 1, 2, 3, 5, 6, 7]), 'split0_train_score': array([0.53149776, 0.53115731, 0.52700688, 0.51764493, 0.4072721 ,\n",
      "       0.1269237 , 0.01603806]), 'split1_train_score': array([0.57214431, 0.57192887, 0.56929932, 0.56103282, 0.4410241 ,\n",
      "       0.13075111, 0.01615552]), 'split2_train_score': array([0.50027709, 0.50011526, 0.49760535, 0.48850961, 0.37276057,\n",
      "       0.11146501, 0.01397604]), 'mean_train_score': array([0.53463972, 0.53440048, 0.53130385, 0.52239579, 0.40701892,\n",
      "       0.12304661, 0.01538987]), 'std_train_score': array([0.02942367, 0.02940734, 0.02942623, 0.02979745, 0.02786904,\n",
      "       0.00833716, 0.00100088])}\n"
     ]
    }
   ],
   "source": [
    "# after the fitting step finishs, then we could get the best parameters that found, also with the best estimator\n",
    "# and the training step info. As bellow:\n",
    "\n",
    "best_score_grid = grid_search.best_score_\n",
    "print('best score: ', best_score_grid)\n",
    "\n",
    "print('*'*30)\n",
    "print(\"Best find parameter:\", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best fitted model: \", best_model)\n",
    "\n",
    "print('*'*30)\n",
    "print('training step evaluation metrics:', grid_search.cv_results_.keys())\n",
    "\n",
    "print('*'*30)\n",
    "print('model training step info:')\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare with base model, grid improve 8.92 %\n",
      "base: 3227.4560610246067\n",
      "grid: 2963.2130044925148\n"
     ]
    }
   ],
   "source": [
    "# here we want to compare with the base model result\n",
    "pred_grid = best_model.predict(xtest)\n",
    "\n",
    "grid_loss = metrics.mean_squared_error(ytest, pred_grid)\n",
    "\n",
    "print(\"compare with base model, grid improve %.2f %s\" % ((base_loss - grid_loss) / grid_loss * 100, '%'))\n",
    "\n",
    "print('base:', base_loss)\n",
    "print('grid:', grid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips\n",
    "One thing should notice that for now, I just to make the tutorial for model selection, in fact, you could choose one more parameter to tune with one pass, and the range of the parameter is what should be learned from machine learning project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search\n",
    "\n",
    "As the grid search is used so many times during my previous work, but one thing should notice that the random search is more effecient to find the best parameters in fact. only the difference with the grid search and random search is random search parameters' value is choosen from some distribution like Gaussian distribution, but we have to define how many values we want to choose with n_iter parameter, I will show you.\n",
    "\n",
    "So here we start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000013D00357828>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expon = distributions.expon()\n",
    "\n",
    "param_distribution = {'alpha': expon}\n",
    "\n",
    "# n_iter is how many values that we want to choose\n",
    "rand_search = RandomizedSearchCV(estimator=lr, param_distributions=param_distribution, n_iter=10, cv=3)\n",
    "\n",
    "# start to train\n",
    "rand_search.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.48824244509444026\n",
      "******************************\n",
      "Best find parameter: {'alpha': 0.09688387165373345}\n",
      "Best fitted model:  Ridge(alpha=0.09688387165373345, copy_X=True, fit_intercept=True,\n",
      "   max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "   tol=0.001)\n",
      "******************************\n",
      "training step evaluation metrics: dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_alpha', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n",
      "******************************\n",
      "model training step info:\n",
      "{'mean_fit_time': array([0.00098745, 0.0006748 , 0.00066503, 0.00099627, 0.00098999,\n",
      "       0.00067639, 0.00098594, 0.0006671 , 0.        , 0.        ]), 'std_fit_time': array([1.13932043e-05, 4.77919635e-04, 4.70246800e-04, 3.54879913e-06,\n",
      "       1.67802572e-05, 4.78490625e-04, 1.64103277e-05, 4.71759584e-04,\n",
      "       0.00000000e+00, 0.00000000e+00]), 'mean_score_time': array([0.00033299, 0.00031463, 0.00033283, 0.00033307, 0.00033283,\n",
      "       0.        , 0.        , 0.00031996, 0.        , 0.00098761]), 'std_score_time': array([4.70920787e-04, 4.44958329e-04, 4.70696004e-04, 4.71033179e-04,\n",
      "       4.70696004e-04, 0.00000000e+00, 0.00000000e+00, 4.52488566e-04,\n",
      "       0.00000000e+00, 1.67282347e-05]), 'param_alpha': masked_array(data=[0.5396058372591854, 1.2741252530133043,\n",
      "                   0.00011438135864308592, 0.360012754853919,\n",
      "                   0.1587095951946739, 0.09688387165373345,\n",
      "                   0.2061146340820805, 0.4239764818070748,\n",
      "                   0.5054525417107485, 0.7739597748607573],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.5396058372591854}, {'alpha': 1.2741252530133043}, {'alpha': 0.00011438135864308592}, {'alpha': 0.360012754853919}, {'alpha': 0.1587095951946739}, {'alpha': 0.09688387165373345}, {'alpha': 0.2061146340820805}, {'alpha': 0.4239764818070748}, {'alpha': 0.5054525417107485}, {'alpha': 0.7739597748607573}], 'split0_test_score': array([0.45120596, 0.37421525, 0.49683155, 0.47375538, 0.49667258,\n",
      "       0.50107201, 0.49203741, 0.46568032, 0.45544059, 0.4236301 ]), 'split1_test_score': array([0.38478847, 0.32815214, 0.41170083, 0.39925128, 0.41161205,\n",
      "       0.41281033, 0.40952261, 0.39423199, 0.3876032 , 0.3655885 ]), 'split2_test_score': array([0.49034166, 0.39889468, 0.55635908, 0.51755814, 0.5456737 ,\n",
      "       0.55138006, 0.53988799, 0.50778737, 0.49543779, 0.4573051 ]), 'mean_test_score': array([0.4419754 , 0.36699725, 0.48810435, 0.46336852, 0.48447991,\n",
      "       0.48824245, 0.48031438, 0.45575291, 0.44602093, 0.41538949]), 'std_test_score': array([0.04355493, 0.02930953, 0.05933725, 0.04882191, 0.0553694 ,\n",
      "       0.05725661, 0.05382812, 0.0468566 , 0.0444952 , 0.0378692 ]), 'rank_test_score': array([ 8, 10,  2,  5,  3,  1,  4,  6,  7,  9]), 'split0_train_score': array([0.459898  , 0.38141065, 0.53149623, 0.48384775, 0.51090244,\n",
      "       0.51796871, 0.50483427, 0.47514094, 0.46432176, 0.43151178]), 'split1_train_score': array([0.49960124, 0.41183019, 0.57214334, 0.52559225, 0.55413533,\n",
      "       0.56135952, 0.54783165, 0.51620832, 0.50444237, 0.46819381]), 'split2_train_score': array([0.42670856, 0.34703178, 0.50027641, 0.45201366, 0.4811718 ,\n",
      "       0.48886118, 0.47458177, 0.44275848, 0.4313465 , 0.397333  ]), 'mean_train_score': array([0.46206927, 0.38009087, 0.53463866, 0.48715122, 0.51540319,\n",
      "       0.5227298 , 0.50908256, 0.47803592, 0.46670354, 0.4323462 ]), 'std_train_score': array([0.02979789, 0.0264703 , 0.02942357, 0.03012902, 0.02995677,\n",
      "       0.02978818, 0.03005464, 0.03005556, 0.02988875, 0.02893482])}\n"
     ]
    }
   ],
   "source": [
    "# evaluate the result like the grid search\n",
    "\n",
    "# after the fitting step finishs, then we could get the best parameters that found, also with the best estimator\n",
    "# and the training step info. As bellow:\n",
    "\n",
    "best_score_grid = rand_search.best_score_\n",
    "print('best score: ', best_score_grid)\n",
    "\n",
    "print('*'*30)\n",
    "print(\"Best find parameter:\", rand_search.best_params_)\n",
    "\n",
    "best_model = rand_search.best_estimator_\n",
    "print(\"Best fitted model: \", best_model)\n",
    "\n",
    "print('*'*30)\n",
    "print('training step evaluation metrics:', rand_search.cv_results_.keys())\n",
    "\n",
    "print('*'*30)\n",
    "print('model training step info:')\n",
    "print(rand_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare with base model, grid improve 10.70 %\n",
      "base: 3227.4560610246067\n",
      "grid: 2915.3913293918163\n"
     ]
    }
   ],
   "source": [
    "# here we want to compare with the base model result\n",
    "pred_grid = best_model.predict(xtest)\n",
    "\n",
    "rand_loss = metrics.mean_squared_error(ytest, pred_grid)\n",
    "\n",
    "print(\"compare with base model, grid improve %.2f %s\" % ((base_loss - rand_loss) / rand_loss * 100, '%'))\n",
    "\n",
    "print('base:', base_loss)\n",
    "print('grid:', rand_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not too much improvement in fact, but don't worry for this sample tutorial. But you have to learn to how to use these two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
